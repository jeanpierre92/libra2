{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resolve the required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # To visualize\n",
    "from tabulate import tabulate #To create pretty tables\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read in the data\n",
    "base_directory = \"/home/jeanpierre/LibraMetrics/containersMetricsFiles/2020_07_24__01_40_18/\"\n",
    "\n",
    "files = [\"merged/jp_mempool_process_incoming_transactions.csv\", \"merged/jp_consensus_process_proposal.csv\", \"merged/jp_consensus_process_new_round.csv\"]\n",
    "\n",
    "data_frames = []\n",
    "for file_name in files:\n",
    "    data_frame = pd.read_csv(base_directory + file_name, names=[\"txns\", \"duration\"])\n",
    "    data_frames.append(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the \"jp_consensus_process_proposal.csv\" into two parts,\n",
    "#as the behaviour when #txns==0 and #txns>0 differs significantly\n",
    "def split(arr, cond):\n",
    "    return arr[cond], arr[~cond]\n",
    "\n",
    "left, right = split(data_frames[1], data_frames[1][\"txns\"] == 0)\n",
    "data_frames.append(right)\n",
    "files.append(\"jp_consensus_process_proposal.csv WHERE #txns>0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert duration from microseconds to milliseconds\n",
    "i = 0\n",
    "while i < len(data_frames):\n",
    "    data_frames[i][\"duration\"] *= .001\n",
    "    i += 1\n",
    "\n",
    "left[\"duration\"] *= 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers that are >{std_from_mean}*std from the mean\n",
    "std_from_mean = 3\n",
    "\n",
    "mean_array = []\n",
    "std_array = []\n",
    "res_array = []\n",
    "\n",
    "i = 0\n",
    "while i < len(data_frames):\n",
    "    mean = data_frames[i].groupby(\"txns\").mean().reset_index()\n",
    "    mean_array.append(mean)\n",
    "\n",
    "    std = data_frames[i].groupby(\"txns\").std().reset_index()\n",
    "    std_array.append(std)\n",
    "    \n",
    "    std_mean = pd.merge(std, mean, on='txns', how='inner')\n",
    "    std_mean.columns = [\"txns\", \"std\", \"mean\"]\n",
    "\n",
    "    res = pd.merge(std_mean, data_frames[i], on='txns', how='inner')\n",
    "    res = res[np.abs(res[\"duration\"]-res[\"mean\"]) <= (std_from_mean*res[\"std\"])]\n",
    "    res_array.append(res)\n",
    "    print(\"Removed \" + str(len(data_frames[i]) - len(res)) + \" outliers out of \" + str(len(data_frames[i])) + \" entries\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Perform linear regression with R-sqaured score with pyplot\n",
    "i = 0\n",
    "while i < len(res_array):\n",
    "    X = res_array[i].iloc[:, 0].values.reshape(-1, 1)\n",
    "    Y = res_array[i].iloc[:, 3].values.reshape(-1, 1)\n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(X, Y)\n",
    "    Y_pred = linear_regressor.predict(X)\n",
    "\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    fig.suptitle(files[i], fontsize=16)\n",
    "    ax = fig.add_subplot()\n",
    "    ax.set_xlabel('#Transactions')\n",
    "    ax.set_ylabel('Duration (milliseconds)')\n",
    "\n",
    "    ax.scatter(X, Y, marker='.', s=1, label='Data point')\n",
    "    ax.plot(X, Y_pred, color='red', label='Linear regression model')\n",
    "\n",
    "    coefficient_of_dermination = r2_score(Y, Y_pred)\n",
    "\n",
    "    #plt.errorbar(mean[\"txns\"], mean[\"duration\"], yerr=0, capsize=5, label=\"errorbar\")\n",
    "    ax.plot(mean_array[i][\"txns\"], mean_array[i][\"duration\"], label=\"Line through sample means\")\n",
    "    ax.plot(std_array[i][\"txns\"], std_array[i][\"duration\"], label=\"Standard Deviation\")\n",
    "\n",
    "    ax.text(0.1, 0.8, \"$R^2={0:.3f}$\".format(coefficient_of_dermination), verticalalignment='bottom', horizontalalignment='right',\n",
    "        transform=ax.transAxes)\n",
    "    plt.legend(loc='upper left')\n",
    "    #plt.savefig('pic.png')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression plot with Seaborn, showing a 95% confidence interval\n",
    "i = 0\n",
    "while i < len(res_array):\n",
    "    fig, ax = plt.subplots(nrows=2, figsize=(16,12), gridspec_kw={'height_ratios':[3,1], 'hspace':0.1})\n",
    "\n",
    "    sns.regplot(x='txns', y='duration', data=res_array[i], ax=ax[0], ci=95, label='Data point', line_kws={\"color\": \"red\"}, scatter_kws={'s':1})\n",
    "    sns.residplot(x='txns', y='duration', data=res_array[i], ax=ax[1], scatter_kws={'s':1})\n",
    "    ax[0].plot(mean_array[i][\"txns\"], mean_array[i][\"duration\"], label=\"Line through sample means\")\n",
    "\n",
    "    ax[0].set_title(files[i], fontsize=16)\n",
    "    ax[0].set_xlabel(\"\")\n",
    "    ax[0].set_ylabel(\"Duration (milliseconds)\")\n",
    "    ax[0].set_xlim(left=0)\n",
    "    ax[0].legend(loc='upper left')\n",
    "\n",
    "    ax[1].set_xlabel(\"#Transactions\")\n",
    "    ax[1].set_ylabel(\"residuals\")\n",
    "    ax[1].set_xlim(left=0, right=ax[0].get_xlim()[1])\n",
    "    ax[1].legend(loc='upper left')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_four_dist_plots(title, data):\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(16,8))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    sns.distplot(data, ax=ax[0][0])\n",
    "    sns.boxplot(data, ax=ax[0][1], fliersize=1, linewidth=1)\n",
    "    sns.boxenplot(data, ax=ax[1][0])\n",
    "    sns.violinplot(data, ax=ax[1][1], inner='quartile')\n",
    "\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    ax[0,0].set_title(\"Distribution\")\n",
    "    ax[0,1].set_title(\"Boxplot\")\n",
    "    ax[1,0].set_title(\"Boxenplot\")\n",
    "    ax[1,1].set_title(\"Violinplot\")\n",
    "\n",
    "    ax[0,0].set_xlabel(\"Duration (milliseconds)\")\n",
    "    ax[0,1].set_xlabel(\"Duration (milliseconds)\")\n",
    "    ax[1,0].set_xlabel(\"Duration (milliseconds)\")\n",
    "    ax[1,1].set_xlabel(\"Duration (milliseconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_four_dist_plots(\"jp_consensus_process_proposal.csv WHERE #txns==0\", left['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_per_timewindow(X, nr_bins):\n",
    "    X_res = []\n",
    "    Y_res = []\n",
    "\n",
    "    end_time = max(X)\n",
    "    part = end_time/nr_bins\n",
    "    for x in range(nr_bins):\n",
    "        position = (part * x) + (0.5 * part)\n",
    "        X_res.append(position)\n",
    "\n",
    "        y_part = X[(X >= (part * x)) & (X < (part * (x+1)))]\n",
    "        Y_res.append(len(y_part)/part)\n",
    "    return X_res, Y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in both client txns start time and end times\n",
    "ac_dataframe = pd.read_csv(base_directory + \"merged/jp_ac_client_transaction.csv\", names=[\"address\", \"sequence_number\", \"timestamp\"])\n",
    "f = open(base_directory + \"container0/jp_blockstore_process_block.csv\")\n",
    "lines = f.read().split(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "dictionary = {\"address\":[], \"sequence_number\":[], \"timestamp\":[]}\n",
    "\n",
    "#Parse blockstore into a dataframe\n",
    "for x in range(len(lines)):\n",
    "    line = lines[x].replace('\"', '')\n",
    "    parts = line.split(\",\")\n",
    "\n",
    "    timestamp = parts[0]\n",
    "    for y in range(1, len(parts)):\n",
    "        acc_seq = parts[y].split(\";\")\n",
    "        dictionary[\"address\"].append(acc_seq[0])\n",
    "        dictionary[\"sequence_number\"].append(acc_seq[1])\n",
    "        dictionary[\"timestamp\"].append(timestamp)\n",
    "\n",
    "blockstore_dataframe = pd.DataFrame(dictionary)\n",
    "blockstore_dataframe[['sequence_number', 'timestamp']] = blockstore_dataframe[['sequence_number', 'timestamp']].apply(pd.to_numeric)\n",
    "\n",
    "#left join to add commit times\n",
    "result = pd.merge(ac_dataframe, blockstore_dataframe, how='left', on=['address', 'sequence_number'], suffixes=['_submit', '_commit'])\n",
    "\n",
    "#calculate the txn_latency and relative_txn_start_time, then add it to the result dataframe\n",
    "txn_latency = result['timestamp_commit'] - result['timestamp_submit']\n",
    "txn_rel_start_time = (result['timestamp_commit'] - result['timestamp_submit'].min())/1000\n",
    "result['txn_latency(ms)'] = txn_latency\n",
    "result['txn_rel_commit_time'] = txn_rel_start_time\n",
    "\n",
    "result.sort_values(by=['timestamp_submit'], inplace=True, ignore_index=True)\n",
    "\n",
    "avg_throughput = len(result) / max(result['txn_rel_commit_time'])\n",
    "print(\"Average Throughput: \" + str(avg_throughput))\n",
    "\n",
    "#Create a scatterplot with 2 Y-axis, txn_latency and txn_througput\n",
    "fig, ax1 = plt.subplots(figsize=(16,8))\n",
    "ax2 = ax1.twinx()\n",
    "#$sns.scatterplot(x=result['txn_rel_commit_time'], y=result['txn_latency(ms)'], label='Data point', size=1, ax=ax1)\n",
    "\n",
    "X, Y = get_counts_per_timewindow(result['txn_rel_commit_time'], int(max(X)/5))\n",
    "ax2.plot(X, Y, color='red', label='Throughput (txn/s)')\n",
    "ax2.set_ylim(bottom=0, top=max(Y)+10)\n",
    "\n",
    "ax1.set_title(\"Txn Latency and Throughput\", fontsize=16)\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Txn commit time (ms)', color='blue')\n",
    "ax2.set_ylabel('Throughput (txn/s)', color='red')\n",
    "ax1.get_legend().remove()\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize txn_latency in distributions\n",
    "create_four_dist_plots(\"Transaction Latency\", result['txn_latency(ms)'])\n",
    "result[['txn_latency(ms)']].describe()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}